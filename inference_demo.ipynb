{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_path = \"Buntan/gec-t5-v1_1-small\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def correct_text(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Corrects the input text using the GEC model.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to be corrected.\n",
    "\n",
    "    Returns:\n",
    "        corrected_text (str): The corrected text.\n",
    "    \"\"\"\n",
    "    tokenized_sentence = tokenizer.encode(\n",
    "        input_text,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    outputs = model.generate(\n",
    "        tokenized_sentence,\n",
    "        max_length=128,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    corrected_text = tokenizer.decode(\n",
    "        outputs[0],\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True,\n",
    "    )\n",
    "\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: My favourite sport is volleyball because I love plays with my friends.\n",
      "Correction: My favourite sport is volleyball because I love playing with my friends.\n",
      "\n",
      "Input Text: I bornt to be a football player.\n",
      "Correction: I born to be a football player.\n",
      "\n",
      "Input Text: The wall of my bedroom are white and the floor is dark grey.\n",
      "Correction: The wall of my bedroom is white and the floor is dark grey.\n",
      "\n",
      "Input Text: I like a many food and drink.\n",
      "Correction: I like a lot of food and drink.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples from BEA 2019 (not in the training data)\n",
    "\n",
    "input_texts = [\n",
    "                \"My favourite sport is volleyball because I love plays with my friends.\",\n",
    "                \"I bornt to be a football player.\",\n",
    "                \"The wall of my bedroom are white and the floor is dark grey.\",\n",
    "                \"I like a many food and drink.\",\n",
    "                ]\n",
    "\n",
    "for input_text in input_texts:\n",
    "    print(f\"Input Text: {input_text}\")\n",
    "    print(f\"Correction: {correct_text(input_text)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gec_model_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
